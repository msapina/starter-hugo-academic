---
title: O logici znanstvenog istra≈æivanja
subtitle: Od Poppera do testiranja hipoteza
# Summary for listings and search engines
summary: random text is random

# Link this post with a project
projects: []

# Date published
date: "2020-12-13T00:00:00Z"

# Date updated
lastmod: "2020-12-13T00:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/CpkOjOcXdUY)'
  focal_point: ""
  placement: 2
  preview_only: false

authors:
- admin

tags:
- Academic

categories:
- Demo
---

## Overview

Pro≈°lo je vi≈°e od deset godina otkako sam prvi put u rukama dr≈æao jednu od onih knjiga koje su me se dojmile da ih uvijek kada pripremam predavanja ponovno uzmem u ruke. Na moju sreƒáu, osoba koja mi je, u ono vrijeme, pru≈æila moguƒánost sudjelovanja u znanstvenom radu je posebna kategorija pametnog ƒçovjeka. Meƒëutim, sam sam sebi postavio pitanje - za≈°to znanost radimo na ovaj naƒçin kakav radimo? Ok, jasno mi je da postoje razliƒçiti metodolo≈°ki pristupi, ali ono ≈°to me zanimalo je postoji li ne≈°to zajedniƒçko tim metodama? Nekakva filozofska osnova? Kako znamo da je ono ≈°to radimo ispravno? Kako mo≈æemo svoje zakljuƒçke generalizirati? Mo≈æemo li uopƒáe? Je li na≈° princip ispravan? I tako, ni ne znajuƒái poƒçeo sam otkrivati neke od temeljnih problema *filozofije znanosti*. Od dedukcije, dedukcije, induktivno-deduktivnog zakljuƒçivanja, testiranja hipoteza, pa sve do kontroverznog *anything goes*.
 Nekoliko je *mind blowing* knjiga bilo, kao ≈°to su *Popperova* **Logika znanstvenog otkriƒáa**, *Kuhnova* **Struktura znanstvenih revolucija** i *Feyerabendova* **Protiv metode**. 
 Ovaj blogpost je namijenjen Popperovom hipotetsko-deduktivnom zakljuƒçivanju i za≈°to radimo to ≈°to radimo. 


Znanstveno istra≈æivanje ima znanstveni cilj i u ostvarenju tog cilja slu≈æi se znanstvenom metodom. Operacionalno definiran cilj znanstvenih istra≈æivanja je provjera hipoteza koje proizlaze iz hipotetiƒçke teorije. Tu treba istaknuti da se hipotetiƒçkom teorijom poku≈°ava objasniti kako se odvijaju pojave i koji su uzroci pojava, a to znaƒçi da takva teorija pretpostavlja zakone po kojima pojave nastaju, o njihovom meƒëuodnosu i kako se odvijaju u prirodi. Znanstveni cilj ima univerzalnu vrijednost jer se odnosi na zakone koji opƒáenito vrijede (4).
 Najƒçe≈°ƒáe primijenjene metode znanstvenog istra≈æivanja jesu: induktivna i deduktivna metoda, metoda analize i sinteze, metoda apstrakcije i konkretizacije, metoda generalizacije i specijalizacije, metoda dokazivanja i opovrgavanja, metoda klasifikacije, metoda deskripcije, metoda kompilacije, komparativna metoda, statistiƒçka metoda, matematiƒçka metoda, metoda modeliranja, eksperimentalna metoda, genetiƒçka metoda. Metoda anketiranja i intervjuiranja, metoda opa≈æanja, metoda brojanja, metoda mjerenja, Delfi metoda(5). 


Induktivna metoda znanstvenog istra≈æivanja je sustavna primjena induktivnog naƒçina zakljuƒçivanja kojim se na temelju analize pojedinaƒçnih ƒçinjenica dolazi do zakljuƒçka o opƒáem sudu. Iz specifiƒçnih pojedinaƒçnih sluƒçajeva zakljuƒçujemo prema opƒáem. Istra≈æivaƒçko razmi≈°ljanje. Postoji vi≈°e vrsta indukcija, kao: potpuna indukcija, nepotpuna indukcija i predikativna indukcija. Kod potpune indukcije zakljuƒçak je na potpunom nabrajanju svih pojedinaƒçnih sluƒçajeva. U praksi se rijetko primjenjuje, a rezultat znaƒçi samo sistematiziranje znanja. Kod ove indukcije zakljuƒçak je potpuno istinit. Nepotpuna indukcija stvara zakljuƒçke na temelju analize ograniƒçenog broja pojedinaƒçnih pojava koji su primjenjivi na ostale pojave iste vrste. ƒåe≈°ƒáe se upotrebljava u znanstvenom istra≈æivanju nego potpuna indukcija. Predikativna indukcija je proces mi≈°ljenja koje se odvija zakljuƒçivanje od jedne klase pojava na drugu klasu, pri ƒçemu se zakljuƒçivanje temelji na sliƒçnosti klasa pojava (5). 

Kako bi Popper rekao: Indukcija nam ne mo≈æe dati sigurnost! Svoju teoriju obrazlo≈æio nam je na primjeru: Europljani su tisuƒáama godina promatrali milijune bijelih labudova. Meƒëutim, istra≈æivanja Australije upoznalo je Europljane s crnim labudovima. Poanta: bez obzira na to koliko se promatranja izvr≈°i i koja potvrde teoriju, uvijek postoji moguƒánost da je buduƒáe promatranje mo≈æe pobiti. Koristeƒái induktivne dokaze, mogli bismo doƒái do teorije da su svi labudovi bijeli. Popper odbacuje logiku indukcije i odbija gledi≈°te da je ona karakteristiƒçna metoda znanstvenog istra≈æivanja i uspostavlja deduktivnu metodu. 
Deduktivna metoda znanstvenog istra≈æivanja je sustavna primjena deduktivnog naƒçina zakljuƒçivanja. Iz opƒáeg zakljuƒçujemo prema pojedinaƒçnom. Logiƒçko razmi≈°ljanje. Deduktivna metoda u znanosti slu≈æi za obja≈°njavanje ƒçinjenica i zakona, za predviƒëanje buduƒáih dogaƒëaja, za otkrivanje novih ƒçinjenica i zakona, za dokazivanje postavljenih teza, za provjeravanje hipoteza i za znanstveno izlaganje. Dedukcija vrijedi samo u okviru utemeljenosti na znanstvenim ƒçinjenicama (5). Tako Popper nagla≈°ava da ne treba biti pogoƒëen ƒçinjenicom da teorija mora biti podvrgnuta najrigoroznijim testovima u jednom dugom periodu vremena, da bi bila verificirana, ono ≈°to moramo prepoznati je da ƒáe takova teorija dobiti visoku dozu potvrƒëivanja, i mo≈æe biti privremeno smatrana kao najbolja raspolo≈æiva teorija sve dok se konaƒçno ne opovrgne ( ako se stvarno ikada opovrgne) i/ili dok se potisne boljom teorijom.
 Metoda opovrgavanja ili falsifikacija se sastoji u dokazivanju pogre≈°ne teze. Izravno ili direktno opovrgavanje sastoji se u pobijanju teze ili argumentacije. Teza se izravno opovrgava onda kada cijeli postupak pobijanja usmjerava na samu tezu, ne uzimajuƒái u obzir njenu suprotnost, odnosno antitezu. Neizravno ili indirektno opovrgavanje sastoji se u dokazu netoƒçnosti teze neizravnim putem. Cijeli postupak se usmjerava na dokazivanju da je antiteza ispravna umjesto da se kao u izravnom opovrgavanju usmjerava na samu tezu. Popper odbacuje indukciju i negira da je ona karakteristiƒçna metoda znanstvenog istra≈æivanja i pristupa, zamjenjuje je principom opovrgljivosti. Tvrdi da je teorija opovrgljiva ako sadr≈æi barem jednu tezu koja ju pobija. To jest znanstvena je ona teorija iz koje se mo≈æe zamisliti takova evidencija ƒçije potvrƒëivanje mo≈æe dovesti do njezina odbacivanja, ili koja sadr≈æi takva riziƒçna predviƒëanja za koja bi se moglo ispostaviti da ju mogu dovesti u pitanje (1). Tako svaki test znanstvene teorije nije drugo nego poku≈°aj njezina odbacivanja ili opovrgavanja, teorija je opovrgljiva ukoliko se opovrgavanje odnosi na ƒçitavu teoriju. Teorija kao takva mo≈æe biti testirana i opovrgnuta ali ne i logiƒçki potvrƒëena. 
Pravio je jasnu razliku logike opovrgavanja i metodologije koja se primijenila unutar te logike. Branjenjem teorije opovrgljivosti, nagla≈°ava ƒçinjenicu da jedna opovrgavajuƒáa ƒçinjenica nije nikada metodolo≈°ki dovoljna da opovrgne teoriju, te da se znanstvene teorije odr≈æe i onda kada postoje ƒçinjenice koje su u suprotnosti s njima. Znanstvene teorije uspostavljene su na puno razliƒçitih naƒçina, i naƒçin na koji znanstvenik formulira teoriju mo≈æe biti biografski zanimljiv, ali nema posljedica za ono ≈°to zanima filozofiju znanosti. Popper tako radije zapoƒçinje s problemom nego s iskustvo. Prema Popperu, znanstvene teorije nisu induktivno izvedene iz iskustva niti je znanstvena empirijska praksa sadr≈æana u nastojanju da se one potvrde i doka≈æu kao istinite, veƒá je sve znanje provizorno, uvjetno, hipotetiƒçno i mi nikada ne mo≈æemo konaƒçno dokazati na≈°e znanstvene teorije, mi ih mo≈æemo samo privremeno prihvatiti dok ne pronaƒëemo neku teorijsku artikulaciju koja ƒáe bolje odgovarati (1). Suoƒçeni smo stalno s mnogobrojnim teorijama koje obja≈°njavaju skup fenomena koje istra≈æujemo. Mi tako preplavljeni s mnogobrojnim teorijama mo≈æemo odbaciti one za koje se mo≈æe pokazati da su krive, i razumno izabrati one koje su ostale meƒëu neopovrgnutim teorijama. Popper nagla≈°ava va≈ænost kritiƒçkog duha u znanosti, duha koji je temelj znanstvene racionalnosti. 




The notion of disbelieving in the null hypothesis is based on the principle of falsification introduced by prominent philosopher of science, Karl Popper (1902-1994). According to Popper (1959), we cannot conclusively affirm a hypothesis, but we can conclusively negate it. The validity of knowledge is tied to the probability of falsification. For example, a very broad and general statement such as "Humans should respect and love each other" can never be wrong and thus does not bring us any insightful knowledge. The more specific a statement is, the higher possibility that the statement can be negated. For Popper, a scientific method is "proposing bold hypotheses, and exposing them to the severest criticism, in order to detect where we have erred." (Popper, 1974, p.68) If the hypothesis can stand "the trial of fire," then we can confirm its validity.

Today we can still find the influence of Popperian principle of falsification in statistical terminology. For instance, in Structural Equation Modeling (SEM), when the resulting equations fail to specify a unique solution, the model is said to be untestable or unfalsifiable, because it is capable of perfectly fitting any data i.e. if a model is "always right" and there is no way to disprove it, this model is useless. A good hypothesis or a good model needs a high degree of specification.

Quantification such as the assertion that "the mean of population A is the same as the population B" is considered a high degree of specification. Following the Popperian logic, the mission of a researcher is to falsify a specific statement rather than to prove that it is right. Therefore, the attempt of falsification leads to the disbelief of the null hypothesis.

Many structural equation modelers (SEM will be introduced in another page) subscribe to the Popperian notion because whenever the researcher found a particular "good" model, there are many other equivalent models that could also fit the data. Following this mode of reasoning, McCoach et al. (2007) stated, "In SEM, it is impossible to confirm a model, we can never actually establish its veracity. Statistical tests and descriptive fit indices can never prove that a model is correct" (p.464).


## Why the null

Careful readers may ask, "Why do we distrust and try to falsify the null hypothesis only? Why don't we apply the same action to the alternate hypothesis?" Indeed, current hypothesis testing procedure is a hybrid of schools of Fisher and Neyman/Pearson. Testing the null hypothesis was introduced by R. A. Fisher (1949) while the alternate hypothesis was suggested by Neyman and Pearson (1928).
We can specify the null hypothesis easily, but we don't know what exactly the alternate hypothesis is. We may hypothesize that there is a mean difference between the two populations, but we cannot point out how wide the gap would be. We don't even know from which of the alternate population the test statistic comes from. At most we can say that the difference is not zero.

Indeed, the logic of hypothesis testing is: Given the null hypothesis is true, how likely it is for the occurrence shown by the data to surface? When the p value is 0.0001, it means that 1 out of 10000 times the data will surface as it did under the assumption of the null.

Because we are confined to start with the null hypothesis only, hypothesis testing is not a fair application of Popperian logic of falsification.

## Cannot prove the null

Nonetheless, in some sense the Popperian approach to hypothesis testing is still correct: we cannot "prove" the hypothesis. As mentioned previously, the logic of hypothesis testing is: Given the null hypothesis how likely we can observe the data in the long run? It can be expressed as: P(D|H). However, usually what we want to know is: given the data how likely the hypothesis, the model, or the theory is correct? It can be written as: P(H|D). It is important to point out that P(D|H) is not the same as P(H|D). Simply put, "if H then D" does not logically imply "if D then H". If this seems too complicated, it can be easily illustrated by classic logics. In classic logics there is a type of fallacy called, affirming the consequent, also known as the converse error. For example,
If the theory is correct, it implies that we could observe Phenomenon X or Data X.
X is observed.
Hence, the theory is correct.
The preceding argument sounds reasonable, but consider the following two examples:
If Thomas Jefferson was assassinated, then Jefferson is dead.
Jefferson is dead.
Therefore Jefferson was assassinated.
If it rains, the ground is wet.
The ground is wet.
It must rain.
In both examples, the premise, which is a conditional statement, is right. However, there are more than one explanations that can fit the observation. A person could die of illness. When the floor is wet, the pipe may be leaking; the city workers may be cleaning the streets. Therefore, the conclusion is invalid. We can apply the same approach to look at a null hypothesis:
If the treatment is ineffective, it implies that there is no performance gap between the control group and the treatment group.
Zero difference is observed.
Hence, the null hypothesis is accepted.
Again, failing to observe a difference could be attributed to other causes. Thus, in hypothesis testing we must state our conclusion as "failing to reject the null hypothesis," but not "accepting the null hypothesis." We have to leave the explanation open to other possibilities.
At most we can say that we either confirm or disconfirm a hypothesis. There is a subtle difference between "prove" and "confirm." The former is about asserting the "truth" but the latter is noting more than showing the fitness between the data and the model. In philosophy of science this type of fitness is called empirical adequacy. When the data and the model cannot fit each other, again, it is problematic to say that we "prove" the null hypothesis. In the O. J. Simpson case or the Casey Anthony's case, there is not enough evidence to convict the suspect, but it doesn't mean that we have proven the otherwise. By the same token, failing to reject the null hypothesis does not mean that the null is true and thus we should accept it. At most we can say we fail to reject the null hypothesis because the absence of evidence is not the evidence of absence (proving the null). In the article entitled "Absence of evidence is not evidence of absence," Altman and Bland (1995) gave this warning to medical researchers: "Randomized controlled clinical trials that do not show a significant difference between the treatments being compared are often called "negative." This term wrongly implies that the study has shown that there is no difference" (p.485).

## Reality

In reality, we can always find problems with the notion of disbelieving in the null hypothesis. Stevens (1992) gave a good example: Suppose a medical researcher conducts a study to examine the safety of a new drug. His hypotheses would be:
Null: The new drug has no health benefits
Alternate: The new drug has health benefits
In this case the doctor should tend to doubt with the alternate hypothesis rather than the null, because if the researcher mistakenly rejects the null and the drug is indeed unsafe, this mistake would cost human lives! In other words, it is a fatal Type I error. There is a real life example in Europe: Once the tranquilizer thalidomide was claimed to be safe but actually the drug was dangerous to pregnant women (cited in Miller & Knapp, 1978).
Nonetheless, McKay Curtis (Personal communication) viewed balancing Type I and Type II errors in drug testing from another perspective:

If a type I error is made and an unsafe drug is approved for use, people could die. This is true. However, Type II errors in this situation could also cost human lives. If a life-saving drug is not approved because of a Type II error, people will also die because they did not have access to the drug. Most people over look this because the consequences of a Type I error are easier to see. It's easier to see that someone has died from a side-effect of an unsafe drug than it is to see that someone has died because he/she didn't have access to a life-saving drug that failed to make it through the statistical hypothesis test. The cost in human lives of a Type II error is just as real as the cost in human lives of a Type I error, even if it is harder to see...The FDA saves lives by preventing bad drugs from coming to market. But the FDA also costs lives by (sometimes) failing to allow effective drugs come to market. Also, because the FDA has seriously increased the costs (in money and time) of new drug development, drug companies only attempt to develop drugs that are very likely to make it through the approval process.
Some philosophers (e.g. D. H. Lewis) may argue against the preceding notion. In philosophy of causation whether absence of certain events could be counted as a cause has been a controversial topic. Nevertheless, Curtis reminded us that the priority of avoiding Type I or Type II errors is not clear-cut.

Further, the discovery of the X-ray was made by "believing" in the null hypothesis instead of disbelieving in it. In 1895 German physicist Roentgen accidentally found a fluorescent glow while working with a cathode ray tube. Later he could see the bone of his hand when this invisible light passed through his flesh. He was shocked, but instead of immediately announcing it as a scientific breakthrough to the world, he worked very hard in an attempt to disconfirm what he found. In other words, the "null" hypothesis is: there is no invisible light that can pass through human tissues and metals. Nevertheless, he and many other scientists could successfully replicate the experiment, and thus the alternate hypothesis was confirmed. The conclusion is more trustworthy because Roentgen was trying to falsify the finding instead of proving what may look good to his career (Kean, 2011).

## Type I and II errors

In most cases the logic of null hypothesis testing follows the principle of "presumed innocence until proven guilty". However, in public health it is often trumped by the precautionary principle, which states that if an action could potentially causing harm to the public or to the ecology, without scientific consensus, the burden of proof that it is not harmful is on the shoulder of the party taking the action. In other words, the precautionary principle prefers "false alarm" (Type I) to "miss" (Type II).
At first glance it makes sense, but the consequence of making a false alarm could be costly. For example, silicone breast implants have been commonly available since 1963, and Dow Corning was the major chemical company that manufactures silicone gel. But after some women who received the implant complained that they were very ill and the possible cause was the silicone gel, the US Food and Drug Administration (FDA) conducted a review and decided there wasn't enough data to show silicone breast implants were safe. As a precautionary measure, the FDA banned all silicone breast implants from 1992-2006. It is important to point out that the FDA did not have evidence to indicate that silicone breast implants are unsafe; rather, it demanded the evidence to ensure its safety. But the FDA's ban had triggered a massive flood of lawsuits against Dow Corning. In 1993 Dow Corning lost more than $287 million. Consequently, Dow Corning was under Chapter 11 protection from 1993-2004. Nonetheless, later many independent scientific studies, including the one conducted by U.S. Institute of Medicine (IOM), found that silicone breast implants do not seem to cause breast cancers or any fatal diseases. But the company's reputation had severely damaged, almost beyond redemption (Gardner, 2008).

It is an ongoing debate about the proper use of hypothesis testing. When we use hypothesis testing, we should be aware of the weakness of the logic. Blindly disbelieving the null hypothesis is unwise. Instead, a careful researcher should balance the Type I and Type II error. Neyman and Pearson (1933a), who introduced the concepts of Type I and Type II errors, recommended that controlling Type II error should be favored in scientific research. Ludbrook and Dudley (1998) argued that in biomedical research it is advisable to control Type I error.

There isn't a clear-cut way for balancing these two errors. The following story illustrates how subjective values would affect the weighing of the hypotheses:

Once a warship is patrolling along the coast. Suddenly an unidentified aircraft appears on the radar screen but the computer system is unable to tell whether it is a friend or a foe.

The captain says:

The null hypothesis is that the incoming aircraft is not hostile. If it is indeed hostile and I don't fire the missile, it is a Type II error. The consequence of committing this Type II error is that we may be attacked and even killed by the jet.
The alternate hypothesis is that the incoming aircraft is hostile. But if it is not hostile and I shoot it down, it is a Type I error. The consequence of making this Type I error is the termination of my career in the Navy.
It seems that the consequence of Type II error is more serious. Therefore, I disbelieve in the null hypothesis. Fire!
The commander shouts "Delay the order!" He argues:
If the null hypothesis is false but we don't react, the consequence is that a few of us, let's say 30, may be killed.
If the alternate hypothesis is false and actually the incoming aircraft is a commercial airliner carrying hundreds of civilian passengers, the consequence of committing a Type I error is killing hundreds of innocent people and even starting a war that may eventually cause more deaths.
I assert that the consequence of Type I error is more severe. Thus, I disbelieve in the alternate hypothesis. Hold the fire!

The above story is exaggerated to make this point: Subjective values affect balancing of Type I and Type II error and our beliefs on null and alternate hypotheses. A similar scenario could be seen in the movie "Crimson Tide" and two real life examples happened in 1987 and 1988. In 1987 an Iraqi jet aircraft fired missile at the USS Stark and killed 37 US Navy personnel. A patrol plane detected the incoming Iraqi jet and sent the information to the USS Stark, but the Captain did not issue a red alert. A year later the USS Vincennes patrolling at the Strait of Hormuz encountered an identified aircraft. This time the Captain ordered to open fire but later it was found that the US warship shot down an Iranian civilian airliner and killed 290 people. While the former mistake is caused by under-reaction, the latter is due to over-reaction.

The founders of hypothesis testing, Neyman and Pearson (1933b) asserted that there is no general rule for balancing errors; in any given case, the determination of "how the balance [between Type I and Type II errors] should be struck, must be left to the investigator." On the contrary, Lipsey (1990) gave a specific guideline: In basic research it is desirable to keep the probability of Type I error low. It is because the nature of basic research is that the researcher should be very conservative about accepting new facts or changing facts of existing knowledge. On the other hand, in applied research it is preferable to minimize the Type II error rate because in a situation where effective treatment is needed and not readily available, a Type II error can represent a great practical loss.

On the other hand, Wang (1993) asserted that the Type I and Type II errors as well as the accept-reject method are useful only for certain engineers in quality control when clear rules of decision are needed. But in general science one can use confidence interval to solve most problems without the help from the analysis of Type I or Type II errors.

In summary, balancing Type I and Type II errors has "nothing to do with statistical theory, but are based instead on context-dependent pragmatic considerations where informed personal judgment plays a vital role" (Hubbard & Bayrri, 2003, p.173).






1. The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site
2. The template can be modified and customised to suit your needs. It's a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a **no-code solution (write in Markdown and customize with YAML parameters)** and having **flexibility to later add even deeper personalization with HTML and CSS**
3. You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more

{{< figure src="https://raw.githubusercontent.com/wowchemy/wowchemy-hugo-modules/master/academic.png" title="The template is mobile first with a responsive design to ensure that your site looks stunning on every device." >}}

## Get Started

- üëâ [**Create a new site**](https://wowchemy.com/templates/)
- üìö [**Personalize your site**](https://wowchemy.com/docs/)
- üí¨ [Chat with the **Wowchemy community**](https://discord.gg/z8wNYzb) or [**Hugo community**](https://discourse.gohugo.io)
- üê¶ Twitter: [@wowchemy](https://twitter.com/wowchemy) [@GeorgeCushen](https://twitter.com/GeorgeCushen) [#MadeWithWowchemy](https://twitter.com/search?q=(%23MadeWithWowchemy%20OR%20%23MadeWithAcademic)&src=typed_query)
- üí° [Request a **feature** or report a **bug** for _Wowchemy_](https://github.com/wowchemy/wowchemy-hugo-modules/issues)
- ‚¨ÜÔ∏è **Updating Wowchemy?** View the [Update Tutorial](https://wowchemy.com/docs/hugo-tutorials/update/) and [Release Notes](https://wowchemy.com/updates/)

## Crowd-funded open-source software

To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.

### [‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy's future ‚ù§Ô∏è](https://wowchemy.com/plans/)

As a token of appreciation for sponsoring, you can **unlock [these](https://wowchemy.com/plans/) awesome rewards and extra features ü¶Ñ‚ú®**

## Ecosystem

* **[Hugo Academic CLI](https://github.com/wowchemy/hugo-academic-cli):** Automatically import publications from BibTeX

## Inspiration

[Check out the latest **demo**](https://academic-demo.netlify.com/) of what you'll get in less than 10 minutes, or [view the **showcase**](https://wowchemy.com/user-stories/) of personal, project, and business sites.

## Features

- **Page builder** - Create *anything* with [**widgets**](https://wowchemy.com/docs/page-builder/) and [**elements**](https://wowchemy.com/docs/content/writing-markdown-latex/)
- **Edit any type of content** - Blog posts, publications, talks, slides, projects, and more!
- **Create content** in [**Markdown**](https://wowchemy.com/docs/content/writing-markdown-latex/), [**Jupyter**](https://wowchemy.com/docs/import/jupyter/), or [**RStudio**](https://wowchemy.com/docs/install-locally/)
- **Plugin System** - Fully customizable [**color** and **font themes**](https://wowchemy.com/docs/customization/)
- **Display Code and Math** - Code highlighting and [LaTeX math](https://en.wikibooks.org/wiki/LaTeX/Mathematics) supported
- **Integrations** - [Google Analytics](https://analytics.google.com), [Disqus commenting](https://disqus.com), Maps, Contact Forms, and more!
- **Beautiful Site** - Simple and refreshing one page design
- **Industry-Leading SEO** - Help get your website found on search engines and social media
- **Media Galleries** - Display your images and videos with captions in a customizable gallery
- **Mobile Friendly** - Look amazing on every screen with a mobile friendly version of your site
- **Multi-language** - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s
- **Multi-user** - Each author gets their own profile page
- **Privacy Pack** - Assists with GDPR
- **Stand Out** - Bring your site to life with animation, parallax backgrounds, and scroll effects
- **One-Click Deployment** - No servers. No databases. Only files.

## Themes

Wowchemy and its templates come with **automatic day (light) and night (dark) mode** built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the [Demo](https://academic-demo.netlify.com/) to see it in action! Day/night mode can also be disabled by the site admin in `params.toml`.

[Choose a stunning **theme** and **font**](https://wowchemy.com/docs/customization) for your site. Themes are fully customizable.

## License

Copyright 2016-present [George Cushen](https://georgecushen.com).

Released under the [MIT](https://github.com/wowchemy/wowchemy-hugo-modules/blob/master/LICENSE.md) license.
